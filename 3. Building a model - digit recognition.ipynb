{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, \n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True, \n",
    "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = t.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = t.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # relu - rectified linear, sigmoid\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        res = F.log_softmax(x, dim=1)\n",
    "        return res\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a random tensor with the needed shape, just to test the net\n",
    "# the negative one in the shape is be ready for any data size\n",
    "X = t.rand((28,28))\n",
    "X = X.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2321, -2.3308, -2.2664, -2.2711, -2.2965, -2.2877, -2.3077, -2.3170,\n",
       "         -2.3206, -2.4055]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "# you can freeze the first few layers, and later only change weights in the \n",
    "# deeper layers. To learn more general and after more specific\n",
    "\n",
    "# learning rate determines the step of iteration towards the min error \n",
    "# steps too large can jump over the max and never see it\n",
    "# steps too low can take ages to compute\n",
    "# decaying learning rate - lr decreases over time, starts big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# epoch - full pass over data\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    for data in trainset:\n",
    "        # data is a batch of feat and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        # how wrong were we?\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# dont optimize, dont calculate the gradients\n",
    "with t.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if t.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(f\"Accuracy: {round(correct/total, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[7].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(t.argmax(net(X[7].view(-1,28*28))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
